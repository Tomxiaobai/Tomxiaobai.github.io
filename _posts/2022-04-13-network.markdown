---
layout: post
read_time: true
show_date: true
title:  network & OS
date:   2021-02-10 13:32:20 -0600
description: 计算机网络知识点总结.
img: posts/20210210/Game_of_Life.jpg
tags: [coding, network]
author: TM
github: https://github.com/Tomxiaobai
---
## NETWORK
* Https的加密机制是一种共享密钥加密和公开密钥加密并用的混合加密机制。

* 对称密钥加密是指加密和解密使用同一个密钥的方式，这种方式存在的最大问题就是密钥发送问题，即如何安全地将密钥发给对方；而非对称加密是指使用一对非对称密钥，即公钥和私钥，公钥可以随意发布，但私钥只有自己知道。发送密文的一方使用对方的公钥进行加密处理，对方接收到加密信息后，使用自己的私钥进行解密。

  　　由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性；但是和对称加密比起来，它非常的慢，所以我们还是要用对称加密来传送消息，但对称加密所使用的密钥我们可以通过非对称加密的方式发送出去。

* 三次握手(我要和你建立链接，你真的要和我建立链接么，我真的要和你建立链接，成功)：

  第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。

  第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。

  第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。

* 第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。

  第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。此时TCP链接处于半关闭状态，即客户端已经没有要发送的数据了，但服务端若发送数据，则客户端仍要接收。

  第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。

  第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。

* **为什么TCP链接需要三次握手，两次不可以么，为什么？**

  * 为了防止 **已失效的链接请求报文突然又传送到了服务端**，因而产生错误。
  * 客户端发出的连接请求报文并未丢失，而是在某个网络节点长时间滞留了，以致延误到链接释放以后的某个时间才到达Server。这时，Server误以为这是Client发出的一个新的链接请求，于是就向客户端发送确认数据包，同意建立链接。若不采用“三次握手”，那么只要Server发出确认数据包，新的链接就建立了。由于client此时并未发出建立链接的请求，所以其不会理睬Server的确认，也不与Server通信；而这时Server一直在等待Client的请求，这样Server就白白浪费了一定的资源。若采用“三次握手”，在这种情况下，由于Server端没有收到来自客户端的确认，则就会知道Client并没有要求建立请求，就不会建立链接。

* **TCP协议如何来保证传输的可靠性**

  * TCP提供一种面向连接的、可靠的字节流服务。其中，面向连接意味着两个使用TCP的应用（通常是一个客户和一个服务器）在彼此交换数据之前必须先建立一个TCP连接。在一个TCP连接中，仅有两方进行彼此通信；而字节流服务意味着两个应用程序通过TCP链接交换8bit字节构成的字节流，TCP不在字节流中插入记录标识符。
  * **对于可靠性，TCP通过以下方式进行保证：**
    * 数据包校验：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时TCP发送数据端超时后会重发数据；
    * 对失序数据包重排序：既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。TCP将对失序数据进行重新排序，然后才交给应用层；
    * 丢弃重复数据：对于重复数据，能够丢弃重复数据；
    * 应答机制：当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒；
    * 超时重发：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；
    * 流量控制：TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP使用的流量控制协议是可变大小的滑动窗口协议。

* **TCP与UDP的区别**

  * TCP是面向连接的，UDP是无连接的；

    TCP是可靠的，UDP是不可靠的；

    TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多的通信模式；

    TCP是面向字节流的，UDP是面向报文的；

    TCP有拥塞控制机制;UDP没有拥塞控制，适合媒体通信；

    TCP首部开销(20个字节)比UDP的首部开销(8个字节)要大；
  
* **TCP如何恢复数据顺序的？TCP的拆包和粘包的作用是什么？**

  * 发送数据的时候会为每个TCP段分配一个seq，方便后续接收数据时能够为乱序的seq进行排序，恢复到原来的样子，确保数据无损的传输

  * 接收方回复发送方，也需要发送seq，因此接收方和发送方很难确保seq是唯一且自增的

  * 因此需要seq和ack来确保TCP数据的发送顺序以及接收方回复消息的对应关系

  <center><img src='./assets/img/posts/20220414/image-20220110203428293.png'></center>

  <center><img src='./assets/img/posts/20220414/image-20220110203809655.png'></center>
  * TCP粘包是为了避免数据段太小导致大量的传输
  
    * 粘包出现的原因：
  
      * 发送端需要等缓冲区满才发送出去，造成粘包
  
      * 接收方不及时接收缓冲区包，造成多个包一起接收
  
      * 粘包情况有两种，一种是粘在一起的包都是完整的数据包，另一种情况是粘在一起的包有不完整的包
  
      * 不是所有的粘包现象都需要处理，若传输的数据为不带结构的连续流数据（如文件传输），则不必把粘连的包分开（简称分包）。但在实际工程应用中，传输的数据一般为带结构的数据，这时就需要做分包处理。
  
        在处理定长结构数据的粘包问题时，分包算法比较简单；在处理不定长结构数据的粘包问题时，分包算法就比较复杂。特别是粘在一起的包有不完整的包的粘包情况，由于一包数据内容被分在了两个连续的接收包中，处理起来难度较大
  
  * TCP拆包的方式（博客）
  
    * 动态缓冲区暂存方式
    * 利用底层的缓冲区来进行拆包
  
  * 对于粘包和拆包问题，常见的解决方案有四种：
  
    - 客户端在发送数据包的时候，每个包都固定长度，比如1024个字节大小，如果客户端发送的数据长度不足1024个字节，则通过补充空格的方式补全到指定长度；
    - 客户端在每个包的末尾使用固定的分隔符，例如\r\n，如果一个包被拆分了，则等待下一个包发送过来之后找到其中的\r\n，然后对其拆分后的头部部分与前一个包的剩余部分进行合并，这样就得到了一个完整的包；
    - 将消息分为头部和消息体，在头部中保存有当前整个消息的长度，只有在读取到足够长度的消息之后才算是读到了一个完整的消息；
    - 通过自定义协议进行粘包和拆包的处理。
    - **附Netty解决**：[方案](https://www.cnblogs.com/AIPAOJIAO/p/10631551.html)
  
* **TCP为什么不一次性把数据发过去呢**？

    <center><img src='./assets/img/posts/20220414/image-20220110202238431.png'></center>
    <center><img src='./assets/img/posts/20220414/image-20220110202327307.png'></center>
  * TCP将数据分成不同的数据部分是根据**buffer缓冲区**的大小定义的，最好每个数据段大小不超过**buffer区域的大小**

* TCP 长连接的方式是怎么实现“当有消息需要发送给某个用户时，能够准确找到这个用户对应的网络连接”？

  * 首先用户有一个登陆的过程： (1)tcp客户端与服务端通过三次握手建立tcp连接；(2)基于该连接客户端发送登陆请求；(3)服务端对登陆请求进行解析和判断，如果合法，就将当前用户的uid和标识当前tcp连接的socket描述符(也就是fd)建立映射关系； (4)这个映射关系一般是保存在本地缓存或分布式缓存中。
    然后，当服务端收到要发送给这个用户的消息时，先从缓存中根据uid查找fd，如果找到，就基于fd将消息推送出去。
    
## RPC
<center><img src='./assets/img/posts/20220414/image-20211227121452694.png'></center>
* 一个 RPC 的核心功能主要有 5 个部分组成，分别是：客户端、客户端 Stub、网络传输模块、服务端 Stub、服务端等

  * 客户端(Client)：服务调用方。
  * 客户端存根(Client Stub)：存放服务端地址信息，将客户端的请求参数数据信息打包成网络消息，再通过网络传输发送给服务端。
  * 服务端存根(Server Stub)：接收客户端发送过来的请求消息并进行解包，然后再调用本地服务进行处理。
  * 服务端(Server)：服务的真正提供者。
  * Network Service：底层传输，可以是 TCP 或 HTTP。

* 一次 RPC 调用流程如下：

  - 服务消费者(Client 客户端)通过本地调用的方式调用服务。
  - 客户端存根(Client Stub)接收到调用请求后负责将方法、入参等信息序列化(组装)成能够进行网络传输的消息体。
  - 客户端存根(Client Stub)找到远程的服务地址，并且将消息通过网络发送给服务端。
  - 服务端存根(Server Stub)收到消息后进行解码(反序列化操作)。
  - 服务端存根(Server Stub)根据解码结果调用本地的服务进行相关处理
  - 服务端(Server)本地服务业务处理。
  - 处理结果返回给服务端存根(Server Stub)。
  - 服务端存根(Server Stub)序列化结果。
  - 服务端存根(Server Stub)将结果通过网络发送至消费方。
  - 客户端存根(Client Stub)接收到消息，并进行解码(反序列化)。
  - 服务消费方得到最终结果。

* RPC 的核心功能主要由 5 个模块组成，如果想要自己实现一个 RPC，最简单的方式要实现三个技术点，分别是：

  - 服务寻址
  - 数据流的序列化和反序列化
  - 网络传输

* **服务寻址**

  服务寻址可以使用 Call ID 映射。在本地调用中，函数体是直接通过函数指针来指定的，但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。

  所以在 RPC 中，所有的函数都必须有自己的一个 ID。这个 ID 在所有进程中都是唯一确定的。

  客户端在做远程过程调用时，必须附上这个 ID。然后我们还需要在客户端和服务端分别维护一个函数和Call ID的对应表。

  当客户端需要进行远程调用时，它就查一下这个表，找出相应的 Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。

  实现方式：服务注册中心

* **序列化和反序列化**

  客户端怎么把参数值传给远程的函数呢?在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。

  但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。

  这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。

  只有二进制数据才能在网络中传输，序列化和反序列化的定义是：

  - 将对象转换成二进制流的过程叫做序列化
  - 将二进制流转换成对象的过程叫做反序列化

  这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程

* **网络传输**

  网络传输：远程调用往往用在网络上，客户端和服务端是通过网络连接的。

  所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把 Call ID 和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。

  只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。

* 尽管大部分 RPC 框架都使用 TCP 协议，但其实 UDP 也可以，而 gRPC 干脆就用了 HTTP2。

  TCP 的连接是最常见的，简要分析基于 TCP 的连接：通常 TCP 连接可以是按需连接(需要调用的时候就先建立连接，调用结束后就立马断掉)，也可以是长连接(客户端和服务器建立起连接之后保持长期持有，不管此时有无数据包的发送，可以配合心跳检测机制定期检测建立的连接是否存活有效)，多个远程过程调用共享同一个连接。

  所以，要实现一个 RPC 框架，只需要把以下三点实现了就基本完成了：

  - Call ID 映射：可以直接使用函数字符串，也可以使用整数 ID。映射表一般就是一个哈希表。
  - 序列化反序列化：可以自己写，也可以使用 Protobuf 或者 FlatBuffers 之类的。
  - 网络传输库：可以自己写 Socket，或者用 Asio，ZeroMQ，Netty 之类。

* **常见的RPC框架：**

  * Thrift FaceBook
  * Dubbo 阿里
  * Grpc Google
  * Motan 微博
  * TRPC 腾讯
## OS
* **协程与线程的区别**

  * 线程和进程都是同步机制，而**协程是异步机制**。
  * 线程是抢占式，而协程是非抢占式的。**需要用户释放使用权切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。**
  * 一个线程可以有多个协程，一个进程也可以有多个协程。
  * **协程不被操作系统内核管理，而完全是由程序控制。**线程是被分割的CPU资源，协程是组织好的代码流程，线程是协程的资源。但协程不会直接使用线程，协程直接利用的是执行器关联任意线程或线程池。
  * **协程能保留上一次调用时的状态**。

* **为什么虚拟地址空间切换会比较耗时？**

  * 进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，页表查找是一个很慢的过程，因此通常使用Cache来缓存常用的地址映射，这样可以加速页表查找，这个Cache就是TLB（translation Lookaside Buffer，TLB本质上就是一个Cache，是用来加速页表查找的）
  * 由于每个进程都有自己的虚拟地址空间，那么显然每个进程都有自己的页表，那么**当进程切换后页表也要进行切换，页表切换后TLB就失效了**，Cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢，而线程切换则不会导致TLB失效，因为线程无需切换地址空间，因此我们通常说线程切换要比较进程切换块，原因就在这里。

* **进程间通信（IPC）方式有哪些？**

  * 管道：管道这种通讯方式有两种限制，一是半双工的通信，数据只能单向流动，二是只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

    管道可以分为两类：匿名管道和命名管道。匿名管道是单向的，只能在有亲缘关系的进程间通信；命名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。

  * 信号：信号是一种比较复杂的通信方式，信号可以在任何时候发给某一进程，而无需知道该进程的状态。

  * 信号量：信号量是一个**计数器**，可以用来控制多个进程对共享资源的访问。它常作为一种**锁机制**，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

  * 消息队列：消息队列是消息的链接表，包括Posix消息队列和System V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。

  * 共享内存：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。

  * Socket：与其他通信机制不同的是，它可用于不同机器间的进程通信。

  * **优缺点**：

    * 管道：速度慢，容量有限；
    * Socket：任何进程间都能通讯，但速度慢；
    * 消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题；
    * 信号量：不能传递复杂消息，只能用来同步；
    * 共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存。
    
  * **总结**： 进程间通信，常见的方式主要有：

    * 基于内存的方式：1）匿名管道；2）信号量；3）消息队列；4）共享内存；
    * 基于磁盘的方式：1）文件；2）命名管道；
    * 基于网络的方式：1）socket；2）消息队列；3）RPC；4）HTTP等各种网络协议

* **线程的分类**

  * **内核级线程**：这类线程依赖于内核，又称为内核支持的线程或轻量级进程。无论是在用户程序中的线程还是系统进程中的线程，它们的创建、撤销和切换都由内核实现。比如英特尔i5-8250U是4核8线程，这里的线程就是内核级线程
  * **用户级线程**：它仅存在于用户级中，这种线程是**不依赖于操作系统核心**的。应用进程利用**线程库来完成其创建和管理**，速度比较快，**操作系统内核无法感知用户级线程的存在**。

* **什么是临界区，如何解决冲突**

  * 每个进程中访问临界资源的那段程序称为临界区，**一次仅允许一个进程使用的资源称为临界资源。**
  * 解决冲突的办法：
    * 如果有若干进程要求进入空闲的临界区，**一次仅允许一个进程进入**，如已有进程进入自己的临界区，则其它所有试图进入临界区的进程必须等待；
    * 进入临界区的进程要在**有限时间内退出**。
    * 如果进程不能进入自己的临界区，则应**让出CPU**，避免进程出现“忙等”现象。

* **进程调度策略有哪几种**

  * **先来先服务**：非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。另外，对`I/O`密集型进程也不利，因为这种进程每次进行`I/O`操作之后又得重新排队。

  * **短作业优先**：非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

  * **最短剩余时间优先**：最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

  * **时间片轮转**：将所有就绪进程按 `FCFS` 的原则排成一个队列，每次调度时，把 `CPU` 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 `CPU` 时间分配给队首的进程。

    时间片轮转算法的效率和时间片的大小有很大关系：因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。

  * **优先级调度**：为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

* **什么是虚拟内存**

  * 虚拟内存就是说，让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。虚拟内存使用部分加载的技术，让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，这样看起来好像内存变大了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虚拟内存。
  
* 网络

  * **telnet**
    有时候我们想知道本机到某个 IP + 端口的网络是否通畅，也就是想知道对方服务器是否在这个端口上提供了服务。这个时候可以用telnet指令。
  * **DNS 查询**
    * **host** 就是一个 DNS 查询工具，如果想追查某种类型的记录，可以使用host -t
    * **dig**指令也是一个做 DNS 查询的
  
  * **如何查看正在 TIME_WAIT 状态的连接数量**
    * netstat -an | grep TIME_WAIT | wc -l
  
* **水平触发 和 边缘触发**

  * 在linux的IO多路复用中有水平触发,边缘触发两种模式,这两种模式的区别如下:
    - 水平触发:如果文件描述符已经就绪可以非阻塞的执行IO操作了,此时会触发通知.允许在任意时刻重复检测IO的状态.select,poll就属于水平触发.
    - 边缘触发:如果文件描述符自上次状态改变后有新的IO活动到来,此时会触发通知.在收到一个IO事件通知后要尽可能多的执行IO操作,因为如果在一次通知中没有执行完IO那么就需要等到下一次新的IO活动到来才能获取到就绪的描述符.信号驱动式IO就属于边缘触发.
    - 其中 **select 和 poll 是水平触发， epoll 有水平触发和边缘触发两种方式** 

## 抓包分析
  - *sudo tcpdump -i any port 21000 -Xnnnlps0*
  - 上述的命令是我们经常用到的抓包分析命令，经常用来测试某个就接口是否可达，或者请求是否到达，通过分析这行命令，我们可以了解Linux下的强大工具tcpdump
  - -i 指定监听的网络接口，any表示任意的
  - -nn 单个 n 表示不解析域名，直接显示 IP；两个 n 表示不解析域名和端口。这样不仅方便查看 IP 和端口号，而且在抓取大量数据时非常高效，因为域名解析会降低抓取速度。
  - -s0 tcpdump 默认只会截取前 96 字节的内容，要想截取所有的报文内容，可以使用 -s number， number 就是你要截取的报文字节数，如果是 0 的话，表示截取报文全部内容。
  - -X 以16进制和ASCII码形式显示每个报文（去掉链路层报头）
  - -l 使标准输出变为缓冲行形式
  - -p 不让网络接口进入混杂模式。默认情况下使用 tcpdump 抓包时，会让网络接口进入混杂模式。一般计算机网卡都工作在非混杂模式下，此时网卡只接受来自网络端口的目的地址指向自己的数据。当网卡工作在混杂模式下时，网卡将来自接口的所有数据都捕获并交给相应的驱动程序。如果设备接入的交换机开启了混杂模式，使用 -p 选项可以有效地过滤噪声。
  - 如何查看某个进程占据的端口号

  ```java
  1. ss -tnlp | grep process_name //ss 一般用于转储套接字统计信息。它能够输出类似于 netstat 输出的信息，但它可以比其它工具显示更多的 TCP 信息和状态信息
  2. netstat -tnlp | grep ssh //默认情况下，netstat 会列出打开的套接字。如果不指定任何地址族，则会显示所有已配置地址族的活动套接字。但 netstat 已经过时了，一般会使用 ss 来替代。
  3. lsof -i -P | grep ssh //lsof 能够列出打开的文件，并列出系统上被进程打开的文件的相关信息。
  ```


## Netty网络模型 
  - IO读写的基本原理 - [Netty、Redis、Zookeeper高并发实战](https://weread.qq.com/web/reader/1e732510718f63a11e7dee2)
    - 上层应用无论是调用操作系统的read，还是调用操作系统的write，都会涉及缓冲区。具体来说，调用操作系统的read，是把数据从内核缓冲区复制到进程缓冲区；而write系统调用，是把数据从进程缓冲区复制到内核缓冲区
    - 为什么需要缓冲区？
      - “外部设备的直接读写，涉及操作系统的中断。发生系统中断时，需要保存之前的进程数据和状态等信息，而结束中断之后，还需要恢复之前的进程数据和状态等信息。为了减少这种底层系统的时间损耗、性能损耗，于是出现了内存缓冲区。”
    - 

