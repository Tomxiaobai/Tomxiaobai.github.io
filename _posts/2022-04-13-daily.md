---
layout: post
read_time: true
show_date: true
title: "Daily record"
date: 2021-04-02
img: posts/20210402/post7-header.webp
tags: [coding, daily, bug fix]
category: theory
author: TM
description: "日常总结记录"
---
## Daily
## 2022-04-18 单机锁 & 分布式锁 [参考](https://time.geekbang.org/column/intro/100056701)
* 单机锁
    - 我们常说的单机锁实际上就是在一个进程内的多个线程操作的一个变量，该变量对于该进程内的所有线程都是可见的，类似于java中的volatile关键字的作用。

    对于在单机上运行的多线程程序来说，锁本身可以用一个变量表示。

    - 变量值为0时，表示没有线程获取锁;

    - 变量值为1时，表示已经有线程获取到锁了。
* 分布式锁

    和单机上的锁类似，分布式锁同样可以用一个变量来实现。客戶端加锁和释放锁的操作逻辑，也和单机上的 加锁和释放锁操作逻辑一致:加锁时同样需要判断锁变量的值，根据锁变量值来判断能否加锁成功;释放锁 时需要把锁变量值设置为0，表明客戶端不再持有锁。

    和线程在单机上操作锁不同的是，在分布式场景下，锁变量需要由一个共享存储系统来维护，只有这样，多个客戶端才可以通过访问共享存储系统来访问锁变量。相应的，加锁和释放锁的操作就变成了读取、 判断和设置共享存储系统中的锁变量值。

    因此为了能够实现分布式锁，则需要多个不同的进程能够访问同一个共享的变量，因此常见的方式则为基于共享的数据库或者缓存实现分布式锁。在目前开发中，常见的分布式锁的实现方式则是通过*Redis*以及*Zookeeper*实现分布式锁。今天主要是了解复习了基于*Redis*的分布式锁的实现方式。

* 基于Redis的分布式锁实现方式

    - 单机Redis

        基于单机的Redis实现分布式锁比较简单，通过key-value形式保存每个客户端的锁，但是在设置锁的时候存在三个步骤->读取锁变量值、判断锁变量值，设置锁变量值。因此，这三个步骤的原子性则决定了加锁的安全性。为了能够保证该三个操作的原子性，我们再*Redis*中常用的主要分为两种模式：
        - 原生命令
        - lua脚本

        对于原生命令，我们则可以通过*SETNX*和*SET*操作来保证，对于LUA脚本，可以详细去学习如何在*Redis*中运行LUA脚本。
    ``` go
    // 加锁
    SETNX lock1 1
    // 业务代码
    TODO
    // 释放锁
    DEL lock1
    ```
    但是该方式存在着一定的问题：

    1. 一直没有执行最后的DEL命令释放锁。因此，锁就一直被这个客戶端持有，其它客戶端无法拿到锁。
    ```python
    SET KEY VALUE [EX seconds | ]
    ```
    2. 假设客戶端B执行了DEL命令释放锁，此时，客戶端A的锁就被误释放了。如果客戶端C正好也在申请加锁，就可以成功获得锁，进而开始操作共享 数据。这样一来，客戶端A和C同时在对共享数据进行操作，数据就会被修改错误，这也是业务层不能接受的。

    为了解决上述两个问题，可以通过设置过期时间，以及为每个客户端生成一个唯一ID，在删除锁的时候进行判定。 
    ```lua
    //释放锁 比较unique_value是否相等，避免误释放
    if redis.call("get",KEYS[1]) == ARGV[1] then
        return redis.call("del",KEYS[1]) 
    else
        return 0 
    end
    ```   
    - 分布式Redis

        目前最常见的分布式Redis锁就是红锁(RedLock)，Redlock算法的基本思路，是让客戶端和多个独立的Redis实例依次请求加锁，如果客戶端能够和半数以上 的实例成功地完成加锁操作，那么我们就认为，客戶端成功地获得分布式锁了，否则加锁失败。主要步骤分为三步：
        1. 客户端获取当前时间戳
        2. 客户端按照顺序依次向N个客户端进行加锁操作
        3. 客户端计算整体的加锁时间

        客戶端只有在满足下面的这两个条件时，才能认为是加锁成功。
        - **条件一**:客戶端从超过半数(大于等于 N/2+1)的Redis实例上成功获取到了锁;
        - **条件二**:客戶端获取锁的总耗时没有超过锁的有效时间。

## 多阶hash
### 什么是多阶hash？
* 多阶hash主要是为了解决hash冲突问题，为了减少在大数据情况下导致原本的hash冲突概率增加，导致数据操作效率降低的问题。
* 多阶hash主要包含两个参数，初始层最多容纳的元素个数N以及阶数M。
* 每一阶可容纳的元素个数为小于等于N的素数，依次作为每个阶数的元素个数。
### 元素的增删改查
* 增：和原本的hash一样，根据Key计算hash值，对N0进行取模获得下标，来判断该阶级是否有空位，如果没有则阶数加1，重复上述流程，直到有空位。若到最后一阶仍没有空位则插入失败。
* 删：获取对应key所在的下标所在索引处置零，并且对其所存储的数据进行删除，其删除方式和链表的删除方式相同。
* 查：直接根据key获取hash值查找元素，从第0阶开始查找，最坏情况需要查找M阶。
### 多阶hash的数据存储方式[相关文章](https://zhuanlan.zhihu.com/p/161967929)
* 系统保留一大块内存，并切分为小的block，每个block具有固定的大小，一个value会占据一个或者多个block

### golang编译bug解决

* 偶遇问题 ``` /usr/local/go/pkg/tool/linux_amd64/link: running g++ failed: exit status 1 ```
    * 解决方案一： 
    
        ```yum install glibc-static.x86_64 libstdc++-static -y ```
    
        若上述仍不能解决问题，则可能是因为 *go-build* 缓存导致的，因此需要清除上次失败的 *go-build* 缓存数据
    * 解决方案二：
        ``` python
        yum install glibc-static.x86_64 libstdc++-static -y
        rm -rf ~/.cache/go-build
        export CXXFLAGS="-stdlib=libstdc++" CC=/usr/bin/gcc CXX=/usr/bin/g++
        ``` 
        该方案应该能彻底解决linux下的 *go-build* 上述问题

### golang内存泄露排查[记录](https://juejin.cn/post/7083412727498014734)

* 常见的内存泄漏排查过程：
    
    1. 首先发现内存的曲线很不正常，或者通过top(htop)发现参数不正常，这时候可以怀疑已经发生了内存泄漏问题。其中，top命令中的load average参数后跟的三个数字代表了系统负载，即任务队列的平均长度。 三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。
    第二行的Task中表示了目前总的进程数，运行的进程数，僵尸进程数等。其他的参数可以也是和cpu或者磁盘数据相关的。其中，比较重要的是进程的各种参数，PID为进程ID，PR为优先级，NI负值表示高优先级，正值表示低优先级；*RES* 表示进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA；SHR表示共享内存大小。这时候，如果发现RES数值较大时，则很大可能gc失败导致，即可能发生了内存泄漏问题。 也可以通过Linux命令查看相关的进程信息 --> *ps -mp pid -o THREAD,tid,time*

    <center><img src='./assets/img/posts/20220414/top_file.png'></center>

    2. golang内存分析神器：pprof 对于经常使用golang的，pprof命令字一定很熟悉，这个能够通过如下命令获取当时的机器内存相关数据，从而进行分析，-inuse_space参数就是当前服务使用的内存情况。
     ```go
        go tool pprof -inuse_space http://ip:amdin_port/debug/pprof/heap
    ```
    也可以通过抓取当时的内存文件进行分析
    ```go
    wget http://ip:amdin_port/debug/pprof/heap？debug=1
    ```
    这时候会在本地生成一个heap?debug=1的文件。

    **golang10次内存泄漏，8次goroutine泄漏，1次真正内存泄漏，还有一次是cgo** 
    可以抓取goroutine进行分析看是否是携程泄漏导致的。
    ```go
    wget http://ip:admin_port/debug/pprof/goroutine?debug=1
    wget http://ip:admin_port/debug/pprof/goroutine?debug=2
    ```
    debug=1就是获取服务当前goroutine的数目和大致信息，debug=2获取服务当前goroutine的详细信息，分别在本地生成了goroutine?debug=1和goroutine?debug=2文件

* SingleFlight初探
    - 主要是通过mutex以及waitGroup的配合使用，达到抑制同类型并发的目的
    ```go
    // 标识了一次调用，同一时刻，针对相同的key，只会出现一次call实例
    type call struct {
    wg sync.WaitGroup // wg负责协同针对同一个key的所有调用协程

    val interface{} // call调用的返回结果，所有相同的调用共享
    err error // call调用的出错信息，所有相同的调用共享

    forgotten bool // call是否被遗忘，如果==true，则同一个key

    dups  int // 如果同一个call被多次调用，则dups自增
    chans []chan<- Result // 在非阻塞调用DoChan，每次调用都会得到一个ch，存于chans
    }

    // group通过mutex实现的一个并发map
    type Group struct {
    mu sync.Mutex       // 主要用于保护m(以及m中的每个call的chans和dups)
    m  map[string]*call // 承载所有的call，key就是调用Do的时候，给的Key
    }
    ```
- 局限性

    - 并非分布式的全局防穿透，多个实例并发仍然存在一定的穿透率。因此，和其他分布式一样，可以选择redis + lua 或者 redis + setnx实现简单的分布式锁，或者使用etcd、zookeeper等中间件
    - 单词调用出现阻塞或者异常时会导致后续的请求均出现阻塞，为防止该情况，可以选择使用异步模式，配合超时控制等方式。


## 一天一个设计模式系列

### 责任链模式
- 行为设计模式
- 请求在链上流转时任何一个满足条件的节点处理完请求后就会停止流转并返回，可以根据业务线进行自己更改
- 责任链的拼接方式主要包括两种：1. 遍历模式，一个节点一个节点的顺序执行；2. 嵌套模式，类似递归，其中嵌套模式常被称为拦截器链或者过滤器链，更易于实现业务流程的切面，如监控业务执行时长、日志输出、权限校验等。



    




